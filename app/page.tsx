'use client';

import React, { useState } from 'react';

export default function Home() {
  // --- éŸ³å£°èªè­˜ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ------------------------------
const SpeechRecognition =
  (typeof window !== 'undefined' &&
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    ((window as any).SpeechRecognition ||
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
      (window as any).webkitSpeechRecognition)) || null;

function startListening() {
  if (!SpeechRecognition) {
    alert('ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“');
    return;
  }

  const recognition = new SpeechRecognition();
  recognition.lang = 'ja-JP';
  recognition.interimResults = false;
  recognition.maxAlternatives = 1;
// eslint-disable-next-line @typescript-eslint/no-explicit-any
  recognition.onresult = (e: any) => {
    const transcript = e.results[0][0].transcript;
    setInput(transcript);                        // å…¥åŠ›æ¬„ã«åæ˜ 
    (document.getElementById('askForm') as HTMLFormElement)?.requestSubmit();
  };

  recognition.onerror = () => alert('éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ');
  recognition.start();
}
// ------------------------------------------------------------

  const [input, setInput] = useState('');
  const [messages, setMessages] = useState<{ type: string; text: string }[]>([]); // ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ç®¡ç†

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!input) return;

    setMessages([...messages, { type: 'user', text: input }]);

    const res = await fetch('/api/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message: input }),
    });

    const data = await res.json();
    if (data.error) {
      alert(data.error);
      return;
    }

    setMessages([...messages, { type: 'bot', text: data.text }]);
// ãƒ–ãƒ©ã‚¦ã‚¶ TTS ã§èª­ã¿ä¸Šã’
// â”€â”€ éŸ³å£°èª­ã¿ä¸Šã’ï¼ˆiOS å¯¾å¿œç‰ˆï¼‰ã“ã“ã‹ã‚‰ â”€â”€
// ===== ã‚·ãƒ³ãƒ—ãƒ«å¤šè¨€èª TTS =====
const utterance = new SpeechSynthesisUtterance(data.text);

// 1è¡Œã ã‘ã®è¶…ã–ã£ãã‚Šåˆ¤å®š
utterance.lang = /[\u3040-\u30ff\u4e00-\u9fff]/.test(data.text)
  ? 'ja-JP'   // æ—¥æœ¬èª or æ¼¢å­—ã‚’å«ã‚€ â†’ æ—¥æœ¬èª
  : 'en-US';  // ãã‚Œä»¥å¤– â†’ è‹±èª

speechSynthesis.cancel();      // ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼ˆiOSå¯¾ç­–ï¼‰
speechSynthesis.speak(utterance);
// ===== ã“ã“ã¾ã§ =====


// æ—¥æœ¬èªãƒœã‚¤ã‚¹ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã®ã‚’å¾…ã£ã¦ã‹ã‚‰å†ç”Ÿ
const setVoiceAndSpeak = () => {
  const jpVoice = speechSynthesis.getVoices().find(v => v.lang === 'ja-JP');
  if (jpVoice) utterance.voice = jpVoice;   // Kyoko / Otoya ãªã©
  speechSynthesis.speak(utterance);
};

if (speechSynthesis.getVoices().length === 0) {
  // iOS ã¯ voices() ãŒé…å»¶ãƒ­ãƒ¼ãƒ‰ã€‚ã‚¤ãƒ™ãƒ³ãƒˆã‚’ä¸€åº¦ã ã‘å¾…ã¤
  speechSynthesis.addEventListener('voiceschanged', setVoiceAndSpeak, { once: true });
} else {
  setVoiceAndSpeak();
}
// â”€â”€ éŸ³å£°èª­ã¿ä¸Šã’ã“ã“ã¾ã§ â”€â”€


    const audio = new Audio(`data:audio/mp3;base64,${data.audio}`);
    audio.play();

    setInput('');
  };

  return (
    <div style={{ padding: '20px', maxWidth: '400px', margin: 'auto' }}>
      <h1>è‡ªæ²»ä½“ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ</h1>
      <div style={{ height: '200px', overflowY: 'auto', border: '1px solid gray' }}>
        {messages.map((m, i) => (
          <p key={i} style={{ color: m.type === 'bot' ? 'blue' : 'green' }}>
            {m.text}
          </p>
        ))}
      </div>
      <form id="askForm"  onSubmit={handleSubmit}>
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="è³ªå•ã‚’å…¥åŠ›ï¼ˆä¾‹: ã”ã¿ã®å‡ºã—æ–¹ï¼Ÿï¼‰"
          style={{ width: '100%' }}
        />
        <button type="submit">é€ä¿¡</button>
      </form>
      <button type="button" onClick={startListening} style={{ marginTop: 8 }}>
  ğŸ¤ è©±ã™
</button>

    </div>
  );
}